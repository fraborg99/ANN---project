{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tic_env import TictactoeEnv, OptimalPlayer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tic Toc Toe environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our 1st game is the famous Tic Toc Toe. You can read about the game and its rules here: https://en.wikipedia.org/wiki/Tic-tac-toe\n",
    "\n",
    "We implemented the game as an environment in the style of games in the [Python GYM library](https://gym.openai.com/). The commented source code is available in the file \"tic_env.py\". Here, we give a brief introduction to the environment and how it can be used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization and attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can initialize the environment / game as following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = TictactoeEnv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which then has the following attributes with the corresponding initial values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'grid': array([[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]]),\n",
       " 'end': False,\n",
       " 'winner': None,\n",
       " 'player2value': {'X': 1, 'O': -1},\n",
       " 'num_step': 0,\n",
       " 'current_player': 'X'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The game is played by two players: player 'X' and player 'O'. The attribute 'current_player' shows whose turn it is. We assume that player 'X' always plays first.\n",
    "\n",
    "The attribute 'grid' is a 3x3 numpy array and presents the board in the real game and the state $s_t$ in the reinfocement learning language. Each elements can take a value in {0, 1, -1}:\n",
    "     0 : place unmarked\n",
    "     1 : place marked with X \n",
    "    -1 : place marked with O \n",
    "        \n",
    "The attribute 'end' shows if the game is over or not, and the attribute 'winner' shows the winner of the game: either \"X\", \"O\", or None.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use function 'render' to visualize the current position of the board:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|- - -|\n",
      "|- - -|\n",
      "|- - -|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "env.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taking actions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The game environment will recieve action from two players in turn and update the grid. At each time, one player can take the action $a_t$, where $a_t$ can either be an integer between 0 to 8 or a touple, corresponding to the 9 possible.\n",
    "\n",
    "Function 'step' is used to recieve the action of the player, update the grid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [1., 0., 0.]]),\n",
       " False,\n",
       " None)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.step(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|- - O|\n",
      "|- O X|\n",
      "|X X O|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'grid': array([[0., 0., 1.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]]),\n",
       " 'end': False,\n",
       " 'winner': None,\n",
       " 'player2value': {'X': 1, 'O': -1},\n",
       " 'num_step': 1,\n",
       " 'current_player': 'O'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.,  0.,  1.],\n",
       "        [ 0., -1.,  0.],\n",
       "        [ 0.,  0.,  0.]]),\n",
       " False,\n",
       " None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.step((1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|- - X|\n",
      "|- O -|\n",
      "|- - -|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'grid': array([[ 0.,  0.,  1.],\n",
       "        [ 0., -1.,  0.],\n",
       "        [ 0.,  0.,  0.]]),\n",
       " 'end': False,\n",
       " 'winner': None,\n",
       " 'player2value': {'X': 1, 'O': -1},\n",
       " 'num_step': 2,\n",
       " 'current_player': 'X'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But not all actions are available at each time: One cannot choose a place which has been taken before. There is an error if an unavailable action is taken:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "There is already a chess on position (0, 2).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-73-d34f74f4d1da>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\OneDrive\\Documenti\\universitÃ \\EPFL\\Semester 2\\Artificial Neural Networks\\project\\tic_env.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, position, print_grid)\u001b[0m\n\u001b[0;32m     59\u001b[0m             \u001b[0mposition\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mposition\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrid\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mposition\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'There is already a chess on position {}.'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mposition\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[1;31m# place a chess on the position\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: There is already a chess on position (0, 2)."
     ]
    }
   ],
   "source": [
    "env.step((0,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reward is always 0 until the end of the game. When the game is over, the reward is 1 if you win the game, -1 if you lose, and 0 besides. Function 'observe' can be used after each step to recieve the new state $s_t$, whether the game is over, and the winner, and function 'reward' to get the reward value $r_t$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 1.]]),\n",
       " False,\n",
       " None)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reward(player='X')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reward(player='O')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example of finishing the game:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 1.,  1.,  1.],\n",
       "        [-1., -1.,  0.],\n",
       "        [ 0.,  0.,  0.]]),\n",
       " True,\n",
       " 'X')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.step(0)\n",
    "env.step(3)\n",
    "env.step(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|X X X|\n",
      "|O O -|\n",
      "|- - -|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 1.,  1.,  1.],\n",
       "        [-1., -1.,  0.],\n",
       "        [ 0.,  0.,  0.]]),\n",
       " True,\n",
       " 'X')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reward(player='X')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reward(player='O')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimal policy for Tic Toc Toe environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fortunately, we know the exact optimal policy for Tic Toc Toe. We have implemented and $\\epsilon$-greedy version of optimal polciy which you can use for the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_player = OptimalPlayer(epsilon = 0., player = 'X')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 0)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_player.act(env.grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'X'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_player.player"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An example of optimal player playing against random player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Game end, winner is player X\n",
      "Optimal player = X\n",
      "Random player = O\n",
      "|O - X|\n",
      "|- X O|\n",
      "|X - -|\n",
      "\n",
      "-------------------------------------------\n",
      "Game end, winner is player X\n",
      "Optimal player = X\n",
      "Random player = O\n",
      "|X O -|\n",
      "|- X O|\n",
      "|- - X|\n",
      "\n",
      "-------------------------------------------\n",
      "Game end, winner is player X\n",
      "Optimal player = X\n",
      "Random player = O\n",
      "|O - O|\n",
      "|- X O|\n",
      "|X X X|\n",
      "\n",
      "-------------------------------------------\n",
      "Game end, winner is player O\n",
      "Optimal player = O\n",
      "Random player = X\n",
      "|X - O|\n",
      "|- O X|\n",
      "|O - X|\n",
      "\n",
      "-------------------------------------------\n",
      "Game end, winner is player None\n",
      "Optimal player = O\n",
      "Random player = X\n",
      "|O X O|\n",
      "|X O X|\n",
      "|X O X|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Turns = np.array(['X','O'])\n",
    "for i in range(5):\n",
    "    env.reset()\n",
    "    grid, _, __ = env.observe()\n",
    "    Turns = Turns[np.random.permutation(2)]\n",
    "    player_opt = OptimalPlayer(epsilon=0., player=Turns[0])\n",
    "    player_rnd = OptimalPlayer(epsilon=1., player=Turns[1])\n",
    "    for j in range(9):\n",
    "        if env.current_player == player_opt.player:\n",
    "            move = player_opt.act(grid)\n",
    "        else:\n",
    "            move = player_rnd.act(grid)\n",
    "\n",
    "        grid, end, winner = env.step(move, print_grid=False)\n",
    "\n",
    "        if end:\n",
    "            print('-------------------------------------------')\n",
    "            print('Game end, winner is player ' + str(winner))\n",
    "            print('Optimal player = ' +  Turns[0])\n",
    "            print('Random player = ' +  Turns[1])\n",
    "            env.render()\n",
    "            env.reset()\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An example of optimal player playing against optimal player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-dbd784ad1d07>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mTurns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'X'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'O'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mgrid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobserve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mTurns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTurns\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpermutation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "Turns = np.array(['X','O'])\n",
    "for i in range(5):\n",
    "    env.reset()\n",
    "    grid, _, __ = env.observe()\n",
    "    Turns = Turns[np.random.permutation(2)]\n",
    "    player_opt_1 = OptimalPlayer(epsilon=0., player=Turns[0])\n",
    "    player_opt_2 = OptimalPlayer(epsilon=0., player=Turns[1])\n",
    "    for j in range(9):\n",
    "        if env.current_player == player_opt.player:\n",
    "            move = player_opt_1.act(grid)\n",
    "        else:\n",
    "            move = player_opt_2.act(grid)\n",
    "\n",
    "        grid, end, winner = env.step(move, print_grid=False)\n",
    "\n",
    "        if end:\n",
    "            print('-------------------------------------------')\n",
    "            print('Game end, winner is player ' + str(winner))\n",
    "            print('Optimal player 1 = ' +  Turns[0])\n",
    "            print('Optimal player 2 = ' +  Turns[1])\n",
    "            env.render()\n",
    "            env.reset()\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q-Learning algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tic_env import TictactoeEnv, OptimalPlayer\n",
    "env = TictactoeEnv()\n",
    "\n",
    "from collections import defaultdict\n",
    "import random\n",
    "class Q_Player:\n",
    "    '''\n",
    "    Description:\n",
    "        A class to implement a Q-Learning optimal player in Tic-tac-toe.\n",
    "\n",
    "    Parameters:\n",
    "        epsilon: float, in [0, 1]. This is a value between 0-1 that indicates the\n",
    "            probability of making a random action instead of the optimal action\n",
    "            at any given time.\n",
    "        alpha: float, in [0, 1]. This is the learning rate\n",
    "        gamma: float, in [0, 1]. This is the discount factor\n",
    "\n",
    "    '''\n",
    "    def __init__(self, epsilon=0.2, player='X',\n",
    "                 qvals = defaultdict(lambda: 0), neighbours = defaultdict(lambda: []), assignment = defaultdict(lambda: 0)):\n",
    "        self.epsilon = epsilon\n",
    "#         self.alpha = alpha\n",
    "#         self.gamma = gamma\n",
    "        self.player = player # 'x' or 'O'\n",
    "        self.qvals = qvals # q values for each state\n",
    "        self.neighbours = neighbours # list of neighouring states for each state\n",
    "        self.assignment = assignment # id to label different grids\n",
    "\n",
    "    def set_player(self, player = 'X', j=-1):\n",
    "        self.player = player\n",
    "        if j != -1:\n",
    "            self.player = 'X' if j % 2 == 0 else 'O'\n",
    "\n",
    "    def empty(self, grid):\n",
    "        '''return all empty positions'''\n",
    "        avail = []\n",
    "        for i in range(9):\n",
    "            pos = (int(i/3), i % 3)\n",
    "            if grid[pos] == 0:\n",
    "                avail.append(pos)\n",
    "        return avail\n",
    "    \n",
    "    def eps_greedyMove(self, grid, assignment, val = None):\n",
    "        \"\"\" Return the move with the optimal Q-value according to a epsilon-greedy policy. \"\"\"\n",
    "        self.assignment = assignment\n",
    "        grid_id = assignment[str(grid)]\n",
    "        if val is None:\n",
    "            val = 1 if self.player == 'X' else -1\n",
    "#         maxq = 0\n",
    "#         finp = self.empty(grid)[0]\n",
    "#         maxq_s = str(self.empty(grid)[0])\n",
    "        print(grid, \"aaaaaaaaaaaaaaa\")\n",
    "        for pos in self.empty(grid):\n",
    "            grid_ = np.copy(grid)\n",
    "            grid_[pos] = val            \n",
    "            action = convert(pos)\n",
    "            next_grid_id = assignment[str(grid_)]\n",
    "            if next_grid_id not in self.neighbours:\n",
    "                self.neighbours[grid_id].append(next_grid_id)\n",
    "#             if self.qvals[grid_string + grid_s] >= self.qvals[grid_string + maxq_s]:\n",
    "#                 finp = pos\n",
    "#                 maxq_s = grid_s\n",
    "            if self.qvals[grid_id][action] < 0:       # before the first update we set to 0 (insted of -99999) the Q-values  \n",
    "                self.qvals[grid_id][action] = 0       # linked to feasible next actions\n",
    "        if random.random() < self.epsilon:\n",
    "            return self.randomMove(grid)#, maxq_s    #return actual move, best move, final best grid\n",
    "        else:\n",
    "            best_move = np.argmax(self.qvals[grid_id])\n",
    "            return best_move, best_move  #return actual move, best move, final best grid\n",
    "        \n",
    "    def return_dicts(self):\n",
    "        return self.assignment, self.neighbours\n",
    "\n",
    "    def randomMove(self, grid):\n",
    "        \"\"\" Chose a random move from the available options. \"\"\"\n",
    "        avail = self.empty(grid)\n",
    "        return avail[random.randint(0, len(avail)-1)]\n",
    "\n",
    "    def act(self, grid, assignment, **kwargs):\n",
    "        \"\"\"\n",
    "        Goes through a hierarchy of moves, making the best move that\n",
    "        is currently available each time (with probabitity 1-self.epsilon).\n",
    "        A touple is returned that represents (row, col).\n",
    "        \"\"\"\n",
    "        return self.eps_greedyMove(grid, assignment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(move):\n",
    "    if type(move) != tuple:\n",
    "        return move\n",
    "    else:\n",
    "        return (move[0]*3 + move[1] % 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 1.]] ccc\n",
      "[[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 1.]] aaaaaaaaaaaaaaa\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'numpy.int64' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-209-c5437d437d0c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[0mmove\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmove\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m         \u001b[0mgrid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwinner\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmove\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprint_grid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ccc\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[0mcurrent_grid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0massignments\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Documenti\\universitÃ \\EPFL\\Semester 2\\Artificial Neural Networks\\project\\tic_env.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, position, print_grid)\u001b[0m\n\u001b[0;32m     57\u001b[0m             \u001b[0mposition\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mposition\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mposition\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mposition\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m             \u001b[0mposition\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mposition\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrid\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mposition\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'There is already a chess on position {}.'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mposition\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'numpy.int64' object is not iterable"
     ]
    }
   ],
   "source": [
    "##TOBEFIXED update not only after q-moves but also after the optimal player's moves\n",
    "Turns = np.array(['X','O'])\n",
    "n_games = 1000\n",
    "winners = []\n",
    "count = []\n",
    "id_ = 0\n",
    "qvals = defaultdict(lambda: np.zeros(9) - 999999)  # we initialize all actions with a negative q value that will be set to 0\n",
    "neighbours = defaultdict(lambda: [])               # for feasible actions to avoid to choose unfeasible actions\n",
    "assignments = defaultdict(lambda: len(assignment))\n",
    "alpha = 0.05\n",
    "gamma = 0.99\n",
    "for i in range(n_games):\n",
    "    print(i)\n",
    "    env.reset()\n",
    "    grid, _, __ = env.observe()\n",
    "    player_opt_1 = OptimalPlayer(epsilon=0.5, player=Turns[i%2])\n",
    "    player_q = Q_Player(epsilon=0.5, player=Turns[1 - i%2], qvals = qvals, neighbours = neighbours)\n",
    "#     qvals = player_q.return_dict()[0]\n",
    "#     neighbours = player_q.return_dict()[1]\n",
    "    for j in range(9):\n",
    "        prev_grid = assignment[str(grid)]\n",
    "        if env.current_player == player_opt_1.player:\n",
    "            move = player_opt_1.act(grid)\n",
    "        else:\n",
    "            move, max_move = player_q.act(grid, assignment)\n",
    "            assignment, neighbours = player_q.return_dicts()\n",
    "            \n",
    "        move = convert(move)\n",
    "        grid, end, winner = env.step(move, print_grid=False)\n",
    "        print(grid, \"ccc\")    \n",
    "        current_grid = assignments[str(grid)]\n",
    "        if end:\n",
    "            winners.append(winner)\n",
    "            if winner == player_q.player:\n",
    "                count.append(1)\n",
    "                qvals[prev_grid][move] += alpha*(1 + gamma*(0 - qvals[prev_grid][move]))\n",
    "            else:\n",
    "                count.append(0)\n",
    "                qvals[prev_grid] += alpha*(-1 + gamma*(0 - qvals[prev_grid][move]))\n",
    "#             print('-------------------------------------------')\n",
    "#             print('Game end, winner is player ' + str(winner))\n",
    "#             print('Optimal player 1 = ' +  Turns[i%2])\n",
    "#             print('Q player 2 = ' +  Turns[1-i%2])\n",
    "            env.render()\n",
    "            env.reset()\n",
    "            break\n",
    "        else:\n",
    "            if env.current_player == player_q.player:\n",
    "                qvals[prev_grid][move] += alpha*(gamma*np.max(qvals[current_grid]) - qvals[prev_grid][move]) # here R = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.<lambda>()>,\n",
       "            {'[[0. 0. 0.]\\n [0. 0. 0.]\\n [1. 0. 0.]]': 85, 9: 86})"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2958b2dc208>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(np.arange(80),[np.sum(i==1)/80 for i in np.split(np.array(count), 80)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_id(grid, assignments):\n",
    "    if len(assignments) == 0:\n",
    "        assignments[str(grid)] = 0\n",
    "        return 0, assignments\n",
    "    elif str(grid) in assignments:\n",
    "        return assignments[str(grid)]\n",
    "    else:\n",
    "        n = len(assignments)\n",
    "        assignments[str(grid)] = n\n",
    "        return n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
